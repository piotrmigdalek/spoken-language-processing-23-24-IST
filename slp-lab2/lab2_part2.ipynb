{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # <span style=\"color:red\">UNDER CONSTRUCTION!!!!</span> -->\n",
    "\n",
    "# Spoken Language Processing - Instituto Superior Técnico\n",
    "## Laboratory Assignment 2 - Native Language Identification challenge\n",
    "\n",
    "# PART 2 - Using pre-trained models\n",
    "\n",
    "\n",
    "This notebook contains the guide and code cells that permit implementing two advanced systems for native language identification based on:\n",
    "- speaker representations (utterance-based) obtained with an x-vector model; \n",
    "- speech representations (frame-based) obtained with a self-supervised learning (SSL) pre-trained model. \n",
    "\n",
    "Besides, the notebook will show how to obtain predictions and score the systems on the development set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before starting\n",
    "\n",
    "Let's import some modules and make some definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Piotr\\Desktop\\spoken-language-processing-23-24-IST\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import csv \n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from pf_tools import CheckThisCell, ETS\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "from speechbrain.utils.data_utils import split_path\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LANGUAGES = ('CHI',  'GER',  'HIN',  'ITA')\n",
    "LANG2ID = {'CHI':1, 'GER':2, 'HIN':3, 'ITA':4}\n",
    "ID2LANG = dict((LANG2ID[k],k)for k in LANG2ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the previous Notebooks, you need to mount Google drive if you are working on Google Colab. Otherwise, you should skip or delete the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raise CheckThisCell ## <---- Remove this torun this cell if you are on Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Like in Part1, the audio data is expected to be in a folder with the following format:\n",
    "\n",
    "```\n",
    "ets_data/\n",
    "├── train/\n",
    "│   └── audio/\n",
    "│       └──wav files\n",
    "│   └── key.lst \n",
    "│\n",
    "└── train100/\n",
    "    └── audio/\n",
    "        └──wav files\n",
    "    └── key.lst\n",
    "... \n",
    "```\n",
    "\n",
    "You must already have this from part 1, so you can set-up your data directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your ETS data should be in this folder c:\\Users\\Piotr\\Desktop\\spoken-language-processing-23-24-IST\\slp-lab2/ets_data/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#raise CheckThisCell ## <---- Remove this after completing/checking this cell\n",
    "\n",
    "CWD = os.getcwd()\n",
    "DATADIR = f'{CWD}/ets_data/' # <--- Change this variable to your working directory containig the ETS data\n",
    "if not os.path.isdir(DATADIR):\n",
    "    os.mkdir(DATADIR)\n",
    "    print(f'WARNING: Your data is not in the folder {DATADIR}')\n",
    "\n",
    "os.chdir(CWD)\n",
    "print(f'Your ETS data should be in this folder {DATADIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to download again the data, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise CheckThisCell\n",
    "\n",
    "os.chdir(DATADIR)\n",
    "\n",
    "# download train\n",
    "!wget http://groups.tecnico.ulisboa.pt/speechproc/pf24/lab2/train.tgz\n",
    "!tar -xzvf train.tgz\n",
    "\n",
    "#download train100\n",
    "!wget http://groups.tecnico.ulisboa.pt/speechproc/pf24/lab2/train100.tgz\n",
    "!tar -xzvf train100.tgz\n",
    "\n",
    "#download dev\n",
    "!wget http://groups.tecnico.ulisboa.pt/speechproc/pf24/lab2/dev.tgz\n",
    "!tar -xzvf dev.tgz\n",
    "\n",
    "#download evl\n",
    "!wget http://groups.tecnico.ulisboa.pt/speechproc/pf24/lab2/evl.tgz\n",
    "!tar -xzvf evl.tgz\n",
    "\n",
    "os.chdir(CWD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using pre-trained speaker embeddings (x-vectors)\n",
    "\n",
    "The goal of this part of the lab is to get familiar with and show how to use pre-trained speaker embedings (a.k.a. x-vectors) for speech classification tasks.\n",
    "\n",
    "There exist plenty of resources and pre-trained models that can be  useful for our task. In particular, x-vectors are the current state of the art approach to obtain speech embeddings that characterize very efficiently speaker or language, among others. X-vectors are neural models typically trained for speaker identification in a supervised way, but also in some cases for other related tasks, like language recognition. Once trained, they can be used to obtain a single embedding vector of fixed dimension for each audio input. This vector corresponds to the activations of one of the layers after the pooling layer. \n",
    "\n",
    "The following are examples of x-vector models available in the `speechbrain` module: \n",
    "\n",
    "- `speechbrain/spkrec-ecapa-voxceleb`: trained using a large speaker corpus for speaker verification: https://huggingface.co/speechbrain/spkrec-ecapa-voxceleb\n",
    "\n",
    "- `speechbrain/lang-id-voxlingua107-ecapa`: trained using a large corpus of 107 languages for language identification: https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa\n",
    "\n",
    "- `speechbrain/lang-id-commonlanguage_ecapa`: trained using a large corpus of 45 languages for language identification: https://huggingface.co/speechbrain/lang-id-commonlanguage_ecapa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell shows how to import one of those models to obtain an embedding vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xvector_model = EncoderClassifier.from_hparams(source=f\"{CWD}/tmp\", savedir=f\"{CWD}/tmp\")\n",
    "\n",
    "signal = xvector_model.load_audio(f'{DATADIR}/train100/audio/train_0005.wav')\n",
    "emb =  xvector_model.encode_batch(signal, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These (very informative) embedding vectors can be used to train simple models for several speech classification tasks, achieving excellent results. In particular, in this lab assignment, we will train a simple linear SVM on top of these x-vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Extracting x-vectors for the ETS datasets\n",
    "\n",
    "Just like in Part1, we will code the feature transformation to process all data and obtain x-vectors. In this case, the function should receive as arguments the audio filename and an instance of `EncoderClassifier` (the x-vector model) and return the numpy array with the features. You must complete the following code using the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 192), numpy.ndarray)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#raise CheckThisCell ## <---- Remove this after completing/checking this cell\n",
    "\n",
    "# This function receives a filename and one encoder model \n",
    "# (for instance, xvector_model object in previous cell example) and returns \n",
    "# the extracted x-vectors as a numpy array of shape (1, embedding_dimension).\n",
    "# Notice that the encoder extractor module generates a softlink to each audio \n",
    "# file. To avoid generating \"junk\", you can delete this link also in the\n",
    "# function \n",
    "\n",
    "def extract_xvec(filename, emb_model):\n",
    "    \n",
    "    signal = xvector_model.load_audio(filename)\n",
    "    embedding = emb_model.encode_batch(signal)\n",
    "\n",
    "    # Remove the \"annoying\" soft-link\n",
    "    _, fl = split_path(filename)\n",
    "    if os.path.islink(fl):\n",
    "        os.remove(fl)\n",
    "\n",
    "    return embedding.squeeze().numpy().reshape(1,-1)\n",
    "\n",
    "# This must return a numpy array of shape (1,256). \n",
    "# The 256 may depend on the specific model\n",
    "emb = extract_xvec(f'{DATADIR}/train100/audio/train_0005.wav' , xvector_model)\n",
    "\n",
    "# Check that this shape and type\n",
    "emb.shape, type(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the x-vectors for all our data sets using the ETS class and store in disk. Like in Part 1, we can keep different transformation configurations in a dictionary for later usage. In this assignment, you can try to different x-vector models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/491M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 491M/491M [00:08<00:00, 61.9MB/s] \n",
      "100%|██████████| 400/400 [8:54:28<00:00, 80.17s/it]      \n",
      "100%|██████████| 217M/217M [00:16<00:00, 13.5MB/s] \n",
      "100%|██████████| 176/176 [16:28<00:00,  5.61s/it]\n",
      "100%|██████████| 209M/209M [00:18<00:00, 12.1MB/s] \n",
      "100%|██████████| 170/170 [17:13<00:00,  6.08s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#raise CheckThisCell ## <---- Remove this after completing/checking this cell\n",
    "\n",
    "transform = { \n",
    "                'spkrec-ecapa-voxceleb' : # <--- You chan look for different models in speechbrain\n",
    "                {\n",
    "                    'audio_transform': \n",
    "                        lambda x : extract_xvec(x, \n",
    "                            emb_model = EncoderClassifier.from_hparams(\n",
    "                                        source=\"speechbrain/spkrec-ecapa-voxceleb\", # <--- You chan look for different models in speechbrain\n",
    "                                        savedir=f\"{CWD}/tmp/spkrec-ecapa-voxceleb\"\n",
    "                                        )\n",
    "                            ), ## <--- You need to modify this here\n",
    "                    'chunk_transform': None,\n",
    "                    'chunk_size': 0,\n",
    "                    'chunk_hop':0   \n",
    "                }\n",
    "            }\n",
    "\n",
    "transform['lang-id-voxlingua107-ecapa'] = {\n",
    "                    'audio_transform': \n",
    "                        lambda x : extract_xvec(x, \n",
    "                            emb_model = EncoderClassifier.from_hparams(\n",
    "                                        source=\"speechbrain/lang-id-voxlingua107-ecapa\", # <--- You chan look for different models in speechbrain\n",
    "                                        savedir=f\"{CWD}/tmp/lang-id-voxlingua107-ecapa\"\n",
    "                                        )\n",
    "                            ), ## <--- You need to modify this here\n",
    "                    'chunk_transform': None,\n",
    "                    'chunk_size': 0,\n",
    "                    'chunk_hop':0   \n",
    "                }\n",
    "\n",
    "# Download and feature extract\n",
    "trainset = 'train100'\n",
    "transform_id = 'spkrec-ecapa-voxceleb' \n",
    "\n",
    "train_ets = ETS(DATADIR, trainset, \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )\n",
    "\n",
    "dev_ets = ETS(DATADIR, 'dev', \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )\n",
    "\n",
    "evl_ets = ETS(DATADIR, 'evl', \n",
    "                 transform_id=transform_id, \n",
    "                 audio_transform=transform[transform_id]['audio_transform'], \n",
    "                 chunk_transform=transform[transform_id]['chunk_transform'],\n",
    "                 chunk_size=transform[transform_id]['chunk_size'], \n",
    "                 chunk_hop=transform[transform_id]['chunk_hop']\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Training the SVM model \n",
    "\n",
    "As mentioned before, our native language identification system will be a simple SVM model (4-classes) using x-vectors as features. Similarly to Part 1, we must iterate the ETS data instances to store the x-vectors and the labels in numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading all data in 2.146310567855835\n",
      "Finished reading all data in 1.358475923538208\n",
      "Finished reading all data in 1.2259979248046875\n"
     ]
    }
   ],
   "source": [
    "# Place train data and reference in a single array train_data and train_label  \n",
    "start = time.time()\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for data, label, basename in train_ets:\n",
    "        train_data.append(data)\n",
    "        train_labels.append(np.full(data.shape[0], label)) \n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')\n",
    "\n",
    "# Place dev data and reference in a single array dev_data and dev_label\n",
    "start = time.time()\n",
    "dev_data = []\n",
    "dev_labels = []\n",
    "dev_filenames = []\n",
    "for data, label, basename in dev_ets:\n",
    "        dev_data.append(data)\n",
    "        dev_labels.append(np.full(data.shape[0], label)) \n",
    "        dev_filenames.append(basename)\n",
    "\n",
    "dev_data = np.concatenate(dev_data)\n",
    "dev_labels = np.concatenate(dev_labels)\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')\n",
    "\n",
    "# Place evl data and reference in a single array evl_data\n",
    "start = time.time()\n",
    "evl_data = []\n",
    "evl_filenames = []\n",
    "for data, label, basename in evl_ets:\n",
    "        evl_data.append(data)\n",
    "        evl_filenames.append(basename)\n",
    "\n",
    "evl_data = np.concatenate(evl_data)\n",
    "\n",
    "print(f'Finished reading all data in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 192), (176, 192), (170, 192))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, dev_data.shape, evl_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use `sklearn` linear SVM to train our classifier and save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC() ### <---- a linear SVM\n",
    "model.fit(train_data, train_labels)  ## <---- train MODEL\n",
    "\n",
    "model_path = f'{DATADIR}/{trainset}/models/'\n",
    "if not os.path.isdir(model_path):\n",
    "    os.mkdir(model_path)\n",
    "    \n",
    "model_name = f'{model_path}/svm_{transform_id}'\n",
    "os.mkdir(f'{model_name}')\n",
    "\n",
    "pickle.dump(model, open(f'{model_name}/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be extremely easy to experiment other models provided in the `sklearn` module, including SVMs with other kernels, Random Forests, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#!pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "best_model_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 5, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best score:  0.865\n",
      "Test Accuracy  : 87.50 %\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'C': [1, 5, 8, 10, 12],\n",
    "    'solver': ['saga', 'liblinear'],\n",
    "    'max_iter': [2000],\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5, n_jobs=-1)\n",
    "grid_search_lr.fit(train_data, train_labels)\n",
    "lr = grid_search_lr.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_lr.best_params_)\n",
    "print(\"Best score: \", grid_search_lr.best_score_)\n",
    "print(\"Test Accuracy  : {:.2f} %\".format(accuracy_score(lr.predict(dev_data), dev_labels)*100))\n",
    "\n",
    "best_model_results.append({'name': 'Logistic Regression',\n",
    "                           'best_gs_score': grid_search_lr.best_score_,\n",
    "                           'test_accuracy': accuracy_score(lr.predict(dev_data), dev_labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 5, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best score:  0.865\n",
      "Test Accuracy  : 84.66 %\n"
     ]
    }
   ],
   "source": [
    "param_grid_svc = {\n",
    "        'C': [0.1, 0.5, 1, 2, 5, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'degree': [2, 3, 4],\n",
    "        'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "grid_search_svc = GridSearchCV(svc, param_grid_svc, cv=5, n_jobs=-1)\n",
    "grid_search_svc.fit(train_data, train_labels)\n",
    "\n",
    "svc = SVC(**grid_search_svc.best_params_)\n",
    "svc.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_svc.best_params_)\n",
    "print(\"Best score: \", grid_search_svc.best_score_)\n",
    "print(\"Test Accuracy  : {:.2f} %\".format(accuracy_score(svc.predict(dev_data), dev_labels)*100))\n",
    "\n",
    "best_model_results.append({'name': 'SVM',\n",
    "                           'best_gs_score': grid_search_svc.best_score_,\n",
    "                           'test_accuracy': accuracy_score(svc.predict(dev_data), dev_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best score:  0.8025\n",
      "Test Accuracy  : 80.68 %\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, n_jobs=-1)\n",
    "grid_search_rf.fit(train_data, train_labels)\n",
    "rf = grid_search_rf.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_rf.best_params_)\n",
    "print(\"Best score: \", grid_search_rf.best_score_)\n",
    "print(\"Test Accuracy  : {:.2f} %\".format(accuracy_score(rf.predict(dev_data), dev_labels)*100))\n",
    "\n",
    "best_model_results.append({'name': 'Random Forest',\n",
    "                           'best_gs_score': grid_search_rf.best_score_,\n",
    "                           'test_accuracy': accuracy_score(rf.predict(dev_data), dev_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'alpha': 10, 'fit_prior': True}\n",
      "Best score:  0.8049999999999999\n",
      "Test Accuracy  : 85.23 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "nb_train = scaler.fit_transform(train_data)\n",
    "nb_dev = scaler.transform(dev_data)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1, 0.5, 1, 2, 5, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_nb = GridSearchCV(nb, param_grid_nb, cv=5, n_jobs=-1)\n",
    "grid_search_nb.fit(nb_train, train_labels)\n",
    "\n",
    "nb = MultinomialNB(**grid_search_nb.best_params_)\n",
    "nb.fit(nb_train, train_labels)\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_nb.best_params_)\n",
    "print(\"Best score: \", grid_search_nb.best_score_)\n",
    "print(\"Test Accuracy  : {:.2f} %\".format(accuracy_score(nb.predict(nb_dev), dev_labels)*100))\n",
    "\n",
    "best_model_results.append({'name': 'Naive Bayes',\n",
    "                           'best_gs_score': grid_search_nb.best_score_,\n",
    "                           'test_accuracy': accuracy_score(nb.predict(nb_dev), dev_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25703\n",
      "[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 192\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best hyperparameters:  {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 32, 'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      "Best score:  0.7525000000000001\n",
      "Test Accuracy  : 78.41 %\n"
     ]
    }
   ],
   "source": [
    "param_grid_lgbm = {\n",
    "        'num_leaves': [32, 64, 128],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.05],\n",
    "        'min_child_samples': [10, 20],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'reg_alpha': [0, 0.1],\n",
    "        'reg_lambda': [0, 0.1]\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "\n",
    "grid_search_lgbm = GridSearchCV(lgbm, param_grid_lgbm, cv=5, n_jobs=-1)\n",
    "grid_search_lgbm.fit(train_data, train_labels)\n",
    "lgbm = grid_search_lgbm.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters: \", grid_search_lgbm.best_params_)\n",
    "print(\"Best score: \", grid_search_lgbm.best_score_)\n",
    "print(\"Test Accuracy  : {:.2f} %\".format(accuracy_score(lgbm.predict(dev_data), dev_labels)*100))\n",
    "\n",
    "best_model_results.append({'name': 'LightGBM',\n",
    "                           'best_gs_score': grid_search_lgbm.best_score_,\n",
    "                           'test_accuracy': accuracy_score(lgbm.predict(dev_data), dev_labels)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Prediction using the x-vector based model\n",
    "\n",
    "Finally, let's predict on both the dev and evl test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE RIGHT MODEL IF YOU NEED TO:\n",
    "# model_name = f'{DATADIR}/{trainset}/models//svm_{transform_id}'\n",
    "# model = pickle.load(open(f'{model_name}/model.pkl', 'rb'))\n",
    "\n",
    "model = lr\n",
    "\n",
    "dev_results = model.predict(dev_data) #  Predict dev\n",
    "evl_results = model.predict(evl_data) #  Predict test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the performance on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CHI       0.89      0.87      0.88        39\n",
      "         GER       0.78      0.82      0.80        44\n",
      "         HIN       0.96      1.00      0.98        47\n",
      "         ITA       0.86      0.80      0.83        46\n",
      "\n",
      "    accuracy                           0.88       176\n",
      "   macro avg       0.87      0.87      0.87       176\n",
      "weighted avg       0.87      0.88      0.87       176\n",
      "\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "ref, hyp = dev_labels, dev_results\n",
    "print(classification_report(ref, hyp, target_names=LANGUAGES))\n",
    "print(accuracy_score(ref, hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(ref, hyp)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.0, 3.0))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=12)\n",
    "plt.ylabel('Actuals', fontsize=12)\n",
    "plt.title(f'Confusion Matrix\\n(Accuracy {100*accuracy_score(ref, hyp):.2f})', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If things went as expected, you should around 85% accuracy result!!\n",
    "\n",
    "At this point, you can explore different x-vector model configurations for feature extraction and alternative models to the linear SVM. Notice that it may be difficult to improve this strong system. Finally, you can generate the final prediction file and make a submission to the  [Kaggle competition](https://www.kaggle.com/t/312cd4200cfb4e138ea9372ce5bc33fd):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = 'train100' ## <--- CHANGE THIS ACCORDINGLY\n",
    "transform_id = 'spkrec-ecapa-voxceleb' ## <--- CHANGE THIS ACCORDINGLY\n",
    "\n",
    "group, system = '00', f'lr_{trainset}_{transform_id}'\n",
    "with open(f'{CWD}/g{group}_{system}.csv', 'w') as file:\n",
    "    csv_writer = csv.writer(file) # CSV writer\n",
    "    csv_writer.writerow(('fileId', 'Lang')) # Header of the CSV\n",
    "\n",
    "    # Save dev results\n",
    "    for lang, file in zip(dev_results, dev_filenames):\n",
    "        csv_writer.writerow((file, LANG2ID[lang]))\n",
    "    # Save evl results\n",
    "    for lang, file in zip(evl_results, evl_filenames):\n",
    "        csv_writer.writerow((file, LANG2ID[lang]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Using self-supervised pre-trained models\n",
    "\n",
    "The goal of this part of the laboratory is to expose students to modern tools and methods for speech classification.\n",
    "In particular, we will use the [s3prl](https://github.com/s3prl/s3prl) toolkit to build a native language identification system based on self-supervised learning (SSL) models as feature extraction.\n",
    "\n",
    "[s3prl](https://github.com/s3prl/s3prl) is an open source toolkit, which stands for Self-Supervised Speech Pre-training and Representation Learning. Self-supervised speech pre-trained models are called upstream in this toolkit and are utilized in various downstream tasks.\n",
    "\n",
    "The toolkit permits pre-training upstream models, load already pre-trained upstream models and/or utilize these upstream models in lots of downstream tasks already defined.\n",
    "\n",
    "For this lab, the faculty team configured a downstream task and a simple model specifically for our native language identification task and data. The model consists of a projection layer, followed by an average pooling, and a linear output layer.\n",
    "\n",
    "In this part of the lab, students are  expected to *play* with the different upstream models to build the best possible native language identification system. \n",
    "In particular, students are encouraged to explore and discover which of the available SSL models can be a better candidate for their classification system. Note that using a large SSL model will make the training process very slow. So, you must choose wisely depending for instance on the reported performance in similar tasks.\n",
    "\n",
    "Besides playing with the different upstream models, interested students can try to modify some of the details of the \"expert\" downstream model. This can be done following some of the many examples already included in the toolkit as a starting point, but it may be challenging. \n",
    "\n",
    "**In contrast to the x-vector based system and the notebook of Part 1, for the SSL system, we will make use of some Python scripts that are part of the S3PRL framework. These are typically run in a terminal, so, some of the following steps may be simpler to run in a terminal, rather than as cell in the Notebook itself.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Installing the S3PRL toolkit\n",
    "Let's start by cloning the repository of the `s3prl` toolkit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 's3prl'...\n",
      "Updating files:  31% (305/975)\n",
      "Updating files:  32% (312/975)\n",
      "Updating files:  33% (322/975)\n",
      "Updating files:  34% (332/975)\n",
      "Updating files:  35% (342/975)\n",
      "Updating files:  36% (351/975)\n",
      "Updating files:  37% (361/975)\n",
      "Updating files:  38% (371/975)\n",
      "Updating files:  39% (381/975)\n",
      "Updating files:  40% (390/975)\n",
      "Updating files:  41% (400/975)\n",
      "Updating files:  42% (410/975)\n",
      "Updating files:  43% (420/975)\n",
      "Updating files:  44% (429/975)\n",
      "Updating files:  44% (435/975)\n",
      "Updating files:  45% (439/975)\n",
      "Updating files:  46% (449/975)\n",
      "Updating files:  47% (459/975)\n",
      "Updating files:  48% (468/975)\n",
      "Updating files:  49% (478/975)\n",
      "Updating files:  50% (488/975)\n",
      "Updating files:  51% (498/975)\n",
      "Updating files:  52% (507/975)\n",
      "Updating files:  53% (517/975)\n",
      "Updating files:  54% (527/975)\n",
      "Updating files:  55% (537/975)\n",
      "Updating files:  56% (546/975)\n",
      "Updating files:  57% (556/975)\n",
      "Updating files:  58% (566/975)\n",
      "Updating files:  59% (576/975)\n",
      "Updating files:  60% (585/975)\n",
      "Updating files:  61% (595/975)\n",
      "Updating files:  62% (605/975)\n",
      "Updating files:  63% (615/975)\n",
      "Updating files:  64% (624/975)\n",
      "Updating files:  65% (634/975)\n",
      "Updating files:  66% (644/975)\n",
      "Updating files:  67% (654/975)\n",
      "Updating files:  68% (663/975)\n",
      "Updating files:  69% (673/975)\n",
      "Updating files:  70% (683/975)\n",
      "Updating files:  71% (693/975)\n",
      "Updating files:  72% (702/975)\n",
      "Updating files:  73% (712/975)\n",
      "Updating files:  74% (722/975)\n",
      "Updating files:  75% (732/975)\n",
      "Updating files:  76% (741/975)\n",
      "Updating files:  77% (751/975)\n",
      "Updating files:  78% (761/975)\n",
      "Updating files:  79% (771/975)\n",
      "Updating files:  80% (780/975)\n",
      "Updating files:  81% (790/975)\n",
      "Updating files:  82% (800/975)\n",
      "Updating files:  83% (810/975)\n",
      "Updating files:  84% (819/975)\n",
      "Updating files:  85% (829/975)\n",
      "Updating files:  86% (839/975)\n",
      "Updating files:  87% (849/975)\n",
      "Updating files:  88% (858/975)\n",
      "Updating files:  89% (868/975)\n",
      "Updating files:  90% (878/975)\n",
      "Updating files:  91% (888/975)\n",
      "Updating files:  92% (897/975)\n",
      "Updating files:  93% (907/975)\n",
      "Updating files:  94% (917/975)\n",
      "Updating files:  95% (927/975)\n",
      "Updating files:  96% (936/975)\n",
      "Updating files:  97% (946/975)\n",
      "Updating files:  98% (956/975)\n",
      "Updating files:  99% (966/975)\n",
      "Updating files: 100% (975/975)\n",
      "Updating files: 100% (975/975), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/s3prl/s3prl.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new folder named  `s3prl/` with the contents of the toolkit has been created. We'll now install the toolkit itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3PRLDIR = CWD + '/s3prl/'\n",
    "os.chdir(S3PRLDIR)\n",
    "#!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Configuring the downstream task\n",
    "Let's create the downstream native language identification task. In the `s3prl/downstream/` there are plenty of examples. The faculty team took one of those as an example to create the configuration needed for this lab assignment. Let's download and copy it to the downstream folder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nie mo�na odnale�� okre�lonego pliku.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Error opening archive: Failed to open 'nli_s3prl_downstream.tgz'\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f'{S3PRLDIR}/s3prl/downstream/') #  change to the downstream folder\n",
    "!wget http://groups.tecnico.ulisboa.pt/speechproc/pf24/lab2/nli_s3prl_downstream.tgz # <--- download the lab specific downstream task\n",
    "!tar -xzvf nli_s3prl_downstream.tgz  #  unzip\n",
    "#!rm nli_s3prl_downstream.tgz\n",
    "os.chdir(S3PRLDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look to the contents of the folder `s3prl/downstream/native_language_identification/`. There are some important files that help to define the task:\n",
    "- `dataset.py`: this file provides the class that permits loading the ETS data. Something similar to the ETS class used in previously, but following the formatting rules of the s3prl toolkit. **You don't need to change anything here**.\n",
    "- `expert.py`: this file defines the expert downstream task. In this case, the expert takes the output of the upstream model (configurable), applies a projection layer, and then a classification model (configurable) to obtain the final predictions. **You don't need to change anything here**.\n",
    "- `model.py`: this file contains the definitions of the model after the projection. We could include several configurations that can later be selected when we run the actual experiment. The model included is just an average pooling (that reduces the time dimension to a single vector) followed by a linear output layer. **You don't need to change anything here, but you may want to explore other configurations following the examples of other downstream tasks included in s3prl**.\n",
    "- `config.yaml`: this file permits configuring some parameters of your experiment, including the path that contains the task data and the training set that is going to be used (either train or train100). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's configure our experiment: \n",
    "\n",
    "Edit the 'file_path' entry in the configuration file `downstream/native_language_identification/config.yaml` to the folder containing the data:\n",
    "\n",
    "```yaml\n",
    "downstream_expert:\n",
    "    datarc:\n",
    "        file_path: \"your_path/ets_data\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And also edit the config file, to use either the \"train100\" partition or the total training data \"train\"  by just editing the following entry of the `downstream/native_language_identification/config.yaml`:\n",
    "\n",
    "```yaml\n",
    "downstream_expert:\n",
    "    datarc:\n",
    "        ...\n",
    "        train: \"train100\"\n",
    "```\n",
    "\n",
    "You may also want to reduce the number of training steps to 1000 or 2000 for quick experimentation of different configurations:\n",
    "\n",
    "```yaml\n",
    "runner:\n",
    "  total_steps: 5000\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2.3 Training the downstream model\n",
    "Now it's time for training. For that, we will use the Pythons script `run_downstream.py` in train mode and in which we will set:\n",
    "- an arbitrary name for identifying this experiment, in which the results will be saved ( `ExpName`)\n",
    "- the upstream model to be used, for instance, `fbank`. You can check for more SSL pretrained available models  here https://s3prl.github.io/s3prl/tutorial/upstream_collection.html\n",
    "- the downstream task, in this case \"native_language_identification\"\n",
    "\n",
    "\n",
    "```bash\n",
    "python3 run_downstream.py -n ExpName -m train -u fbank -d native_language_identification\n",
    "```\n",
    "\n",
    "Since this can take a while (actually, a lot depending on the chosen upstream model and your  computational resources), you probably want to run this in a terminal, rather than inside the Notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'{S3PRLDIR}/s3prl')\n",
    "!python3 run_downstream.py -n fbank -m train -u fbank -d native_language_identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HINT: if the training process is interrupted for some reason, you can continue from the last saved checkpoint (a checkpoint is saved every 200 iterations):\n",
    "\n",
    "```bash\n",
    "python3 run_downstream.py -m train -e result/downstream/fbank/states-XXXX.ckpt\n",
    "```\n",
    "\n",
    "### 2.2.4 Classification and performance of the dev set\n",
    "\n",
    "The training process created a folder containing some training results `result/downstream/{ExpName}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(f'{S3PRLDIR}/s3prl')\n",
    "!ls result/downstream/fbank/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting files: \n",
    "- `dev_predict.txt` contains the predictions on the dev set, \n",
    "- `dev-best.ckpt` contains the model parameters for the best checkpoint,\n",
    "- `log.log` contains information of the training process, including the identification accuracy in the train and dev sets. \n",
    "\n",
    "Let's load the prediction and reference files to compute the performance of our system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = [line.strip().split()[-1] for line in open(f'result/downstream/fbank/dev_predict.txt')]\n",
    "ref = [line.strip().split()[-1] for line in open(f'result/downstream/fbank/dev_truth.txt')]\n",
    "\n",
    "print(classification_report(ref, hyp, target_names=LANGUAGES))\n",
    "print(accuracy_score(ref, hyp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was disappointing!! The `fbank` is **a very bad upstream model!!!**. \n",
    "\n",
    "The goal of this lab is for you to get familiar with and experiment with some of the most popular speech SSL models. You can start with those commented in the theoretical lessons or the ones that have shown good performance in similar tasks. Be careful (and wise) in your decisions: experiments may be slow! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Classification of the evl set \n",
    "\n",
    "Now that we already trained our downstream model, we can use it to predict  the blind evl set. For this purpose, we will use again the `run_downstream.py` script in evaluate mode and we need to select the actual model to use:\n",
    "\n",
    "\n",
    "```bash\n",
    "python3 run_downstream.py -m evaluate -e result/downstream/fbank/dev-best.ckpt\n",
    "```\n",
    "\n",
    "NOTE: Ignore the test accuracy reported at the end (we  don't have the groundtruth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 run_downstream.py -m evaluate -e result/downstream/fbank/dev-best.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_predict.txt` file contains the predictions of this model for the evl set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Create the final predictions file and submit to the challenge\n",
    "\n",
    "Like in Part 1, we will create the predictions file in the expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset = 'train100'\n",
    "upstream_id = 'fbank' ## <--- CHANGE THIS ACCORDINGLY\n",
    "group, system = '00', f'ssl_{trainset}_{upstream_id}'\n",
    "\n",
    "filename_dev = f'{S3PRLDIR}/s3prl/result/downstream/{upstream_id}/dev_predict.txt'\n",
    "filename_evl = f'{S3PRLDIR}/s3prl/result/downstream/{upstream_id}/test_predict.txt'\n",
    "\n",
    "\n",
    "with open(f'{CWD}/g{group}_{system}.csv', 'w') as file:\n",
    "    \n",
    "    csv_writer = csv.writer(file) # CSV writer\n",
    "    csv_writer.writerow(('fileId', 'Lang')) # Header of the CSV\n",
    "\n",
    "    results_dev = [l.strip().split() for l in open(filename_dev, 'r')]\n",
    "    results_evl = [l.strip().split() for l in open(filename_evl, 'r')]\n",
    "\n",
    "    # Save dev results\n",
    "    for file_id, lang in results_dev:\n",
    "        file_id = file_id.split('-')[-1]\n",
    "        lang = LANG2ID[lang]\n",
    "        csv_writer.writerow((file_id, lang))\n",
    "        \n",
    "    # Save evl results\n",
    "    for file_id, lang in results_evl:\n",
    "        file_id = file_id.split('-')[-1]\n",
    "        lang = LANG2ID[lang]\n",
    "        csv_writer.writerow((file_id, lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can submit your prediction(s) in the  [Kaggle competition](https://www.kaggle.com/t/312cd4200cfb4e138ea9372ce5bc33fd).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contacts and support\n",
    "You can contact the professors during the classes or the office hours.\n",
    "\n",
    "Particularly, for this second laboratory assignment, you should contact Prof. Alberto Abad: alberto.abad@tecnico.ulisboa.pt\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
